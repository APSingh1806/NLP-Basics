{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Stemming**\n",
        "Stemming is the process of reducing a word to its stem that affixes to suffixes and prefixes or to the roots of words known as lemma.\n"
      ],
      "metadata": {
        "id": "f9lsqkgPKTPX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wfc-tfKlKMue"
      },
      "outputs": [],
      "source": [
        "## Classification problem\n",
        "## comment s on the prodcuts is a positive review or negative review\n",
        "## Review ---> eating, eat, eaten--> will reduce to \"eat\" [ going , go, goes] ---> will reduce to \"go\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eaten\", \"puts\", \"putting\", \"writing\", \"writes\", \"programming\",\"programs\",\"history\", \"finally\", \"finalized\"]"
      ],
      "metadata": {
        "id": "kcCwdisMLaED"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PorterStemmer**\n"
      ],
      "metadata": {
        "id": "93NZ6nRvL9ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "HF5nW0LrL9QV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "CV92FonOLy12"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"--->\"+stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJioFgysMUEE",
        "outputId": "4dd63e87-5673-47e4-ff38-4eb6a49c0ce2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating--->eat\n",
            "eats--->eat\n",
            "eaten--->eaten\n",
            "puts--->put\n",
            "putting--->put\n",
            "writing--->write\n",
            "writes--->write\n",
            "programming--->program\n",
            "programs--->program\n",
            "history--->histori\n",
            "finally--->final\n",
            "finalized--->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem('congratulations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j0oOavpnMhwl",
        "outputId": "2b44719e-a3f2-469d-ec34-16bbae911947"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'congratul'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## The above word 'congratul','histori' does not have any meaning, so this is major disadvantage of stemming.\n",
        "## So this problem will be fixed by lemmetization"
      ],
      "metadata": {
        "id": "x4I_d6jYM3B_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idR74iCANaPf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RegexpStemmer class**\n",
        "\n",
        "NLTK has RegexpStemmer class with the help of which we can easily implement regular Expression Stemmer algorithm. It basically Takes a single regular expression and removes any prefix or suffix that matches the expresion,"
      ],
      "metadata": {
        "id": "SnrvqI1dNfSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "qRRx-F5INe67"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$',min=4)"
      ],
      "metadata": {
        "id": "yF_0lC3oOV8W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('eating')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tzNG1fsWPK9d",
        "outputId": "00cf2ef9-f7c2-4975-c06e-9e69fcf54041"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('ingeating')"
      ],
      "metadata": {
        "id": "CLwi2Xe0PnSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7977376a-aba9-432e-8a7e-9e45f2d8a5d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ingeat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lfokVDcjzEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Snowball Stemmer**\n",
        "\n",
        "It is a stemming algorithm which is also known as Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
      ],
      "metadata": {
        "id": "4I7YXxpcj7R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "kiNz9cRJj-MA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowballsstemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "0NI-qx62kzDa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+snowballsstemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FwfBIk1lHoO",
        "outputId": "bd617362-8d44-4f44-d398-23367d62d2e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating----->eat\n",
            "eats----->eat\n",
            "eaten----->eaten\n",
            "puts----->put\n",
            "putting----->put\n",
            "writing----->write\n",
            "writes----->write\n",
            "programming----->program\n",
            "programs----->program\n",
            "history----->histori\n",
            "finally----->final\n",
            "finalized----->final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowballsstemmer.stem('fucking')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Nj1MBr6hlisT",
        "outputId": "1640db8b-c0a0-4205-91bd-f154211d0664"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fuck'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem('fairly'), snowballsstemmer.stem('fairly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIv3_uillvH7",
        "outputId": "9ba0a820-97f9-4fc0-ec65-d661470ba3b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairli', 'fair')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem('sportingly'), snowballsstemmer.stem('sportingly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uxwIjB5mM4l",
        "outputId": "fea8b383-aded-46a1-8678-388709585deb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sportingli', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sccNCwUBmmmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEDSdLuhmqwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q7jpaoj1mqtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization\n"
      ],
      "metadata": {
        "id": "Wpo3UernmrXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet Lemmatizer\n",
        "\n",
        "Lemmatixation technique is like stemming. The output we will get fer lemmatization is called 'lemma', which is a root word rather than soot stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing."
      ],
      "metadata": {
        "id": "6U-4k_kinfNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses a morphy() function to the Wordnet CorpusReader class to find a lemma. Let us understand it with an example."
      ],
      "metadata": {
        "id": "B8oO01gzoUZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Q&A , chatbots, text summarization ----> lemmatization used in"
      ],
      "metadata": {
        "id": "naO0Ia1Um0xH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "Hm3wKRSxpFk4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "P4CEpJjQpPGZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47dfc4e1",
        "outputId": "907b83f4-e0ba-485e-8726-5f13ba4ae8bb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "POS - Noun-n\n",
        "Verb - v\n",
        "adjective - a\n",
        "adverb - r\n",
        "'''\n",
        "lemmatizer.lemmatize(\"going\", pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tK8j5AmlpXMe",
        "outputId": "b8d0bb42-5df4-4516-80e1-ca3782abe5dd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+'---->'+lemmatizer.lemmatize(word, pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BLpeVZKqCqX",
        "outputId": "4bb6e7b1-4e61-4c93-e4a9-f7eabbfb7225"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eat\n",
            "puts---->put\n",
            "putting---->put\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->history\n",
            "finally---->finally\n",
            "finalized---->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('fairly', pos='v'), lemmatizer.lemmatize('sportingly',pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CdfP33Tqg16",
        "outputId": "b503db0a-3a5d-4f4c-eedc-1a438866daab"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairly', 'sportingly')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86y1yu9bq8pV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}